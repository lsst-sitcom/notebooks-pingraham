{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to determine the sensitivity matrix from CWFS data\n",
    "## It first finds the pairs of CWFS images in the EFD\n",
    "## It then fits the data a reports the zernikes\n",
    "## Then plots the relationships and fits a slope for the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio \n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "from lsst_efd_client import EfdClient, resample\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily needed to run at summit\n",
    "import os\n",
    "os.environ[\"LSST_DDS_DOMAIN\"] = 'lsatmcs'\n",
    "os.environ[\"OSPL_URI\"] = \"file:///home/patrickingraham/ospl.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efd_client = EfdClient('summit_efd')\n",
    "efd_client = EfdClient('ncsa_efd') #summit_efd currently offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for all the `endReadout` events on the timespan of the night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Time(\"2020-02-19T05:35\", format='isot', scale='tai')\n",
    "t2 = Time(\"2020-02-19T11:18\", format='isot', scale='tai')#+TimeDelta(8.*24.*60*60., format='sec', scale='tai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_readout = await efd_client.select_time_series(\"lsst.sal.ATCamera.logevent_endReadout\", \n",
    "                                           [\"imageName\", \"exposureTime\", \"groupId\", \"imageType\"], t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end_readout['imageType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now match each entry. For each `i` item with `intra` in the name, there must be an `i+1` with `extra` otherwise it is not a pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_images = []\n",
    "extra_images = []\n",
    "intra_times = []\n",
    "extra_times = []\n",
    "intra_exptimes = []\n",
    "extra_exptimes = []\n",
    "\n",
    "i = 0\n",
    "npairs = 0\n",
    "nmiss = 0\n",
    "\n",
    "while i < len(end_readout)-2:\n",
    "    intra = end_readout['imageName'][i]\n",
    "    extra = end_readout['imageName'][i+1]\n",
    "    \n",
    "    #skip known bad files\n",
    "    if intra == 'AT_O_20200218_000179' and extra == 'AT_O_20200218_000180':\n",
    "        i+=2\n",
    "        continue\n",
    "    \n",
    "    if (end_readout['groupId'][i] == end_readout['groupId'][i+1]) and (end_readout['groupId'][i+1] != end_readout['groupId'][i+2]) and (end_readout['imageType'][i] == 'ENGTEST'):\n",
    "        print(f\"Got a pair: {intra} x {extra}\")\n",
    "        intra_images.append(intra)\n",
    "        extra_images.append(extra)\n",
    "        intra_times.append(end_readout.index[i])\n",
    "        extra_times.append(end_readout.index[i+1])\n",
    "        intra_exptimes.append(end_readout['exposureTime'][i])\n",
    "        extra_exptimes.append(end_readout['exposureTime'][i+1])\n",
    "        i+=2\n",
    "        npairs+=1\n",
    "    else:\n",
    "#         print(f\"No Match: {intra} x {extra}\")\n",
    "        nmiss+=1\n",
    "        i+=1\n",
    "\n",
    "print(f\"Got {npairs} pairs and {nmiss} misses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = np.zeros(npairs, dtype=[('intra', '<U35'), \n",
    "                                     ('extra', '<U35'), \n",
    "                                     ('az', float), \n",
    "                                           ('el', float), \n",
    "                                           ('rot_pos', float),\n",
    "                                           ('x', float), \n",
    "                                           ('y', float), \n",
    "                                           ('z', float), \n",
    "                                           ('u', float), \n",
    "                                           ('v', float), \n",
    "                                           ('w', float), \n",
    "                                     ('m1_pressure', float),\n",
    "                                     ('dz', float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(npairs):\n",
    "    \n",
    "    t1 = Time(intra_times[i], scale='tai') - TimeDelta(intra_exptimes[i], format='sec', scale='tai') - TimeDelta(180., format='sec', scale='tai')\n",
    "    t2 = Time(extra_times[i], scale='tai') - TimeDelta(1., format='sec', scale='tai')\n",
    "\n",
    "    azel = await efd_client.select_time_series(\"lsst.sal.ATMCS.mount_AzEl_Encoders\", \n",
    "                                               [\"elevationCalculatedAngle99\", \"azimuthCalculatedAngle99\"], t1, t2)\n",
    "    rotator = await efd_client.select_time_series(\"lsst.sal.ATMCS.mount_Nasmyth_Encoders\",\n",
    "                                                  [\"nasmyth2CalculatedAngle99\"], t1, t2)\n",
    "    hexapod = await efd_client.select_time_series(\"lsst.sal.ATHexapod.command_moveToPosition\",\n",
    "                                                  [\"x\", \"y\", \"z\", \"u\", \"v\", \"w\"], t1, t2)\n",
    "    m1_pressure = await efd_client.select_time_series(\"lsst.sal.ATPneumatics.m1AirPressure\",\n",
    "                                                  [\"pressure\"], t1, t2)\n",
    "    #offset = await efd_client.select_time_series(\"lsst.sal.ATAOS.command_applyAxisOffset\",\n",
    "    #                                             [\"*\"], t1, t2)\n",
    "    offset = await efd_client.select_time_series(\"lsst.sal.ATAOS.logevent_hexapodCorrectionCompleted\",\n",
    "                                                 [\"hexapod_x\", \"hexapod_y\", \"hexapod_z\", \"hexapod_u\", \"hexapod_v\", \"hexapod_w\"], t1, t2)\n",
    "    \n",
    "    if len(hexapod) < 2:\n",
    "         print(f\"Could not get hexapod position for pair {i+1}: {intra_images[i]} x {extra_images[i]}\")\n",
    "         continue\n",
    "\n",
    "    rot_pos = np.mean(rotator['nasmyth2CalculatedAngle99'])\n",
    "    el = np.mean(azel['elevationCalculatedAngle99'])\n",
    "    az = np.mean(azel['azimuthCalculatedAngle99'])\n",
    "    # Need to get most recently commanded hexapod correction position\n",
    "    # should always be the last two values of an the array (except for \n",
    "    # z which will move for intra/extra)\n",
    "#     x = (hexapod['x'][len(hexapod)-2]+hexapod['x'][len(hexapod)-1])/2.\n",
    "#     y = (hexapod['y'][len(hexapod)-2]+hexapod['y'][len(hexapod)-1])/2.\n",
    "#     z = (hexapod['z'][len(hexapod)-2]+hexapod['z'][len(hexapod)-1])/2.\n",
    "#     u = (hexapod['u'][len(hexapod)-2]+hexapod['u'][len(hexapod)-1])/2.\n",
    "#     v = (hexapod['v'][len(hexapod)-2]+hexapod['v'][len(hexapod)-1])/2.\n",
    "#     w = (hexapod['w'][len(hexapod)-2]+hexapod['w'][len(hexapod)-1])/2.\n",
    "\n",
    "    x = (offset['hexapod_x'][-2]+offset['hexapod_x'][-2])/2.\n",
    "    y = (offset['hexapod_y'][-2]+offset['hexapod_y'][-2])/2.\n",
    "    z = (offset['hexapod_z'][-2]+offset['hexapod_z'][-2])/2.\n",
    "    u = (offset['hexapod_u'][-2]+offset['hexapod_u'][-2])/2.\n",
    "    v = (offset['hexapod_v'][-2]+offset['hexapod_v'][-2])/2.\n",
    "    w = (offset['hexapod_w'][-2]+offset['hexapod_w'][-2])/2.\n",
    "\n",
    "    m1 = np.mean(m1_pressure['pressure'])\n",
    "    dz = round((offset['hexapod_z'][-1] - offset['hexapod_z'][-2])/2.,3)\n",
    "    match_data[i] = (f\"{intra_images[i]}.fits\", f\"{extra_images[i]}.fits\", az, el, rot_pos, x, y, z, u, u, w, m1, dz)\n",
    "\n",
    "    print(t1,t2,az, el, rot_pos, x, y, z, u, u, w,dz)\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rot_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(match_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(df)):\n",
    "#     print(f\"{df['intra'][i]}: {df['el'][i]+df['rot_pos'][i]}: dz={df['dz'][i]}\")\n",
    "# # df['intra'],df['el']+df['rot_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"20200123_match.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now reduce the data for each pair to get the zernikes from fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.DataFrame.from_csv(\"20200123_match.csv\")\n",
    "df2 = pd.read_csv(\"20200123_match.csv\")\n",
    "# but need to add all the zernike terms from teh fitting\n",
    "df2['zern_defocus_nm'] = np.zeros(len(df2))\n",
    "df2['zern_xastig_nm'] = np.zeros(len(df2))\n",
    "df2['zern_yastig_nm'] = np.zeros(len(df2))\n",
    "df2['zern_xcoma_nm'] = np.zeros(len(df2))\n",
    "df2['zern_ycoma_nm'] = np.zeros(len(df2))\n",
    "df2['zern_xtrefoil_nm'] = np.zeros(len(df2))\n",
    "df2['zern_ytrefoil_nm'] = np.zeros(len(df2))\n",
    "df2['zern_sphereical_nm'] = np.zeros(len(df2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_data = np.zeros(npairs, dtype=[('intra', '<U35'), \n",
    "#                                      ('extra', '<U35'), \n",
    "#                                      ('az', float), \n",
    "#                                            ('el', float), \n",
    "#                                            ('rot_pos', float),\n",
    "#                                            ('x', float), \n",
    "#                                            ('y', float), \n",
    "#                                            ('z', float), \n",
    "#                                            ('u', float), \n",
    "#                                            ('v', float), \n",
    "#                                            ('w', float), \n",
    "#                                      ('m1_pressure', float),\n",
    "#                                      ('dz', float),\n",
    "#                                     ('zern_defocus_nm', float),\n",
    "#                                     ('zern_xastig_nm', float),\n",
    "#                                     ('zern_yastig_nm', float),\n",
    "#                                     ('zern_xcoma_nm', float),\n",
    "#                                     ('zern_ycoma_nm', float),\n",
    "#                                     ('zern_xtrefoil_nm', float),\n",
    "#                                     ('zern_ytrefoil_nm', float),\n",
    "#                                     ('zern_sphereical_nm', float),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires new pandas version to use\n",
    "# df2 = pd.DataFrame.read_csv(\"20200123_match.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lsst.ts.externalscripts.auxtel.latiss_cwfs_align import LatissCWFSAlign\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = LatissCWFSAlign(index=1, remotes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.dataPath='/project/shared/auxTel/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visitID_from_filename(filename):\n",
    "    # Expects AT_O_20200218_000167.fits\n",
    "    # parse out visitID from filename - this is highly annoying\n",
    "    tmp=filename.split('_')\n",
    "    prefix=tmp[2] # dayobs without the dashes\n",
    "\n",
    "    # Don't remember why I used int here... whitespace? \n",
    "    # surely fixable but bigger fish.\n",
    "    suffix='{:05d}'.format(int(tmp[3].split('.')[0])) # SEQNUM, but need to trim extra 0 in obsid\n",
    "    visitID = int((prefix+suffix))\n",
    "    #print(visitID)\n",
    "    return visitID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logging\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "# if you want logging\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.level = logging.DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(df2)):\n",
    "#for n in [len(df2)-2]:   \n",
    "    script.angle = 0.\n",
    "    script.intra_visit_id = get_visitID_from_filename(df2['intra'][n])\n",
    "    script.extra_visit_id = get_visitID_from_filename(df2['extra'][n])\n",
    "\n",
    "    start_time=time.time()\n",
    "    await script.run_cwfs()\n",
    "    end_time=time.time()\n",
    "    print('WFE fitting for visitIDs {0} and {1} took {2:0.3f} seconds'.format(script.intra_visit_id, script.extra_visit_id,end_time-start_time)) # 56.7s\n",
    "\n",
    "    # Display fitting results?\n",
    "    if (True):\n",
    "        # plot zernikes\n",
    "        x = np.arange(9)+4\n",
    "        plt.plot(x, script.algo.zer4UpNm[:9], 'o-', label=f'{script.dz}')\n",
    "        xlim = plt.xlim()\n",
    "        plt.plot(np.arange(15), np.zeros(15)+50, 'b--')\n",
    "        plt.plot(np.arange(15), np.zeros(15)-50, 'b--')\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylabel(\"Zernike coeff (nm)\")\n",
    "        plt.xlabel(\"Zernike index\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        \n",
    "    if (True):\n",
    "        # plot image and mask\n",
    "        fig1 = plt.figure(2, figsize=(12,8))\n",
    "        ax11 = fig1.add_subplot(121)\n",
    "        ax11.set_title(\"defocus 0.8 - intra\")\n",
    "        ax11.imshow(script.I1[0].image0)\n",
    "        ax11.contour(script.algo.pMask) \n",
    "        ax12 = fig1.add_subplot(122)\n",
    "        ax12.set_title(\"defocus 0.8 - extra\")\n",
    "        ax12.imshow(script.I2[0].image0)\n",
    "        ax12.contour(script.algo.pMask) \n",
    "        \n",
    "    # Put results into data structure\n",
    "    # This will throw errors but don't know how to do this properly!\n",
    "    df2['zern_defocus_nm'][n] = script.algo.zer4UpNm[0]\n",
    "    df2['zern_xastig_nm'][n] = script.algo.zer4UpNm[1]\n",
    "    df2['zern_yastig_nm'][n] = script.algo.zer4UpNm[2]\n",
    "    df2['zern_xcoma_nm'][n] = script.algo.zer4UpNm[3]\n",
    "    df2['zern_ycoma_nm'][n]= script.algo.zer4UpNm[4]\n",
    "    df2['zern_xtrefoil_nm'][n] = script.algo.zer4UpNm[5]\n",
    "    df2['zern_ytrefoil_nm'][n] = script.algo.zer4UpNm[6]\n",
    "    df2['zern_sphereical_nm'][n] = script.algo.zer4UpNm[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV file\n",
    "df2.to_csv(\"20200123_match_zerns.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabola(x,b, x0, a):\n",
    "    return b + a*(x-x0)**2 \n",
    "def line(x,b, m):\n",
    "    return b + m*x \n",
    "def invparabola(y,b,x0,a):\n",
    "    return x0+np.sqrt((y-b)/a)\n",
    "def invline(y,b,m):\n",
    "    return (y-b)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = pd.DataFrame.from_csv(\"20200123_match_zerns.csv\")\n",
    "# use below for pandas 1.0+\n",
    "df3 = pd.read_csv(\"20200123_match_zerns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Y-Coma as a function of Y-hexapod decentering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(0,10) # drop the last value\n",
    "inds = [0,1,2,3,5,6,7,8]\n",
    "\n",
    "xdata=df3['y'][inds]\n",
    "ydata=df3['zern_ycoma_nm'][inds]\n",
    "\n",
    "plt.plot(xdata,ydata,'o')\n",
    "x=np.arange(np.min(xdata), np.max(xdata), np.abs(np.max(xdata) - np.min(xdata))/100 )\n",
    "popt,pcov = curve_fit(line, xdata, ydata)\n",
    "print('Wavefront X-Coma as a function of Hexapod displacement',popt)\n",
    "\n",
    "plt.plot(x,line(x, *popt))\n",
    "# plt.xlabel('Hexapod displacement in the plane')\n",
    "plt.ylabel('Zernike Coefficient in nm')\n",
    "plt.title('Wavefront Y-Coma as a function of hexapod Y-displacement')\n",
    "plt.show()\n",
    "\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(240+200)/ (-6 - -3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Defocus as a function of Y-hexapod decentering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coma as a function of x,y offset (8-23, 31-35)\n",
    "inds = np.arange(0,11)\n",
    "inds = [0,1,2,3,5,6,7,8]\n",
    "\n",
    "xdata=df3['y'][inds]\n",
    "ydata=df3['zern_defocus_nm'][inds]\n",
    "\n",
    "plt.plot(xdata,ydata,'o')\n",
    "x=np.arange(np.min(xdata), np.max(xdata), np.abs(np.max(xdata) - np.min(xdata))/100 )\n",
    "popt,pcov = curve_fit(line, xdata, ydata)\n",
    "print('Wavefront X-Coma as a function of Hexapod displacement',popt)\n",
    "\n",
    "plt.plot(x,line(x, *popt))\n",
    "# plt.xlabel('Hexapod displacement in the plane')\n",
    "plt.ylabel('Zernike Coefficient in nm')\n",
    "plt.title('Wavefront Defocus as a function of y-hexapod displacement')\n",
    "plt.show()\n",
    "\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
